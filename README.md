# AI Resume Reviewer

An intelligent resume review and job matching system that uses AI to analyze resumes against job descriptions.

## ğŸš€ Quick Deploy

### Railway (Backend) + Vercel (Frontend)

**One-click deployment:**

1. **Backend (Railway):**
   - Go to [Railway.app](https://railway.app)
   - Connect your GitHub repo
   - Set Root Directory: `backend`
   - Add environment variables
   - Deploy

2. **Frontend (Vercel):**
   - Go to [Vercel.com](https://vercel.com)
   - Connect your GitHub repo
   - Set Root Directory: `frontend`
   - Add `NEXT_PUBLIC_API_URL` environment variable
   - Deploy

ğŸ“– **Detailed deployment guide:** [DEPLOYMENT.md](./DEPLOYMENT.md)

## âœ¨ Features

- **PDF Resume Processing**: Extract and analyze text from PDF resumes
- **AI-Powered Analysis**: Uses multiple LLM APIs (Groq, Together AI, Cohere) for comprehensive analysis
- **Semantic Similarity**: BERT-based semantic matching between resume and job description
- **Skills Extraction**: Advanced skills matching with importance weighting
- **Multi-Layer Validation**: Ensures accurate scoring with confidence metrics
- **Modern Web Interface**: Built with Next.js and Tailwind CSS
- **RESTful API**: FastAPI backend with comprehensive endpoints

## ğŸ—ï¸ Tech Stack

### Backend
- **FastAPI**: Modern Python web framework
- **Supabase**: Database for storing review history
- **Machine Learning**: 
  - Sentence Transformers for semantic similarity
  - spaCy for NLP and skills extraction
  - Multiple LLM APIs for intelligent analysis
- **PDF Processing**: pdfplumber and PyMuPDF
- **Deployment**: Railway (recommended) or Vercel

### Frontend
- **Next.js 15**: React framework with App Router
- **TypeScript**: Type-safe development
- **Tailwind CSS**: Modern styling
- **Deployment**: Vercel

## ğŸ“ Project Structure

```
AI_ResumeReviewer/
â”œâ”€â”€ backend/                 # Railway deployment
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI application
â”‚   â”‚   â”œâ”€â”€ config.py       # Configuration settings
â”‚   â”‚   â”œâ”€â”€ embedding.py    # AI analysis engine
â”‚   â”‚   â”œâ”€â”€ supabase.py     # Database operations
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â””â”€â”€ review.py   # API endpoints
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â”œâ”€â”€ railway.json       # Railway configuration
â”‚   â””â”€â”€ env.example        # Environment variables template
â”œâ”€â”€ frontend/               # Vercel deployment
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # Next.js App Router
â”‚   â”‚   â””â”€â”€ components/    # React components
â”‚   â”œâ”€â”€ package.json       # Node.js dependencies
â”‚   â”œâ”€â”€ vercel.json        # Vercel configuration
â”‚   â””â”€â”€ next.config.ts     # Next.js configuration
â”œâ”€â”€ DEPLOYMENT.md          # Detailed deployment guide
â”œâ”€â”€ setup-local.bat        # Windows local setup
â”œâ”€â”€ setup-local.sh         # Unix local setup
â””â”€â”€ README.md             # This file
```

## ğŸš€ Local Development

### Prerequisites
- Python 3.11+
- Node.js 18+
- Git

### Quick Start

**Windows:**
```bash
# Run the setup script
setup-local.bat
```

**Unix/Linux/macOS:**
```bash
# Make script executable
chmod +x setup-local.sh

# Run the setup script
./setup-local.sh
```

### Manual Setup

**Backend:**
```bash
cd backend
pip install -r requirements.txt
python -m spacy download en_core_web_sm
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev
```

**Access:**
- Frontend: http://localhost:3000
- Backend: http://localhost:8000
- API Docs: http://localhost:8000/docs

## ğŸ”§ Environment Variables

### Backend (Railway)
```env
GROQ_API_KEY=your_groq_api_key
COHERE_API_KEY=your_cohere_api_key
TOGETHER_API_KEY=your_together_api_key
SUPABASE_URL=your_supabase_url
SUPABASE_KEY=your_supabase_key
```

### Frontend (Vercel)
```env
NEXT_PUBLIC_API_URL=https://your-railway-backend-url.railway.app
```

## ğŸ“Š API Endpoints

### POST `/api/v1/match`
Analyze resume against job description

**Request:**
- `file`: PDF resume file
- `job_description`: Job description text

**Response:**
```json
{
  "final_similarity_score": 0.85,
  "final_similarity_percentage": 85.0,
  "similarity_category": "Excellent Match (85-100%)",
  "skills_analysis": {
    "coverage_percentage": 0.75,
    "direct_match_count": 15,
    "total_job_skills": 20,
    "missing_skills": ["Docker", "Kubernetes"]
  },
  "llm_details": {
    "strengths": ["Strong technical background", "Relevant experience"],
    "gaps": ["Missing cloud experience"],
    "recommendations": ["Consider AWS certification"]
  }
}
```

### GET `/health`
Health check endpoint

### GET `/api/v1/reviews`
Get recent resume reviews (if Supabase configured)

## ğŸ¯ Features in Detail

### AI Analysis Engine
- **Multi-LLM Ensemble**: Uses Groq, Together AI, and Cohere APIs
- **Fallback Strategy**: Automatically switches between APIs for reliability
- **Semantic Analysis**: BERT-based similarity scoring
- **Skills Matching**: Fuzzy matching with importance weighting

### PDF Processing
- **Multiple Extractors**: pdfplumber and PyMuPDF for reliability
- **Text Cleaning**: Advanced text preprocessing
- **Error Handling**: Graceful fallbacks for corrupted files

### Skills Analysis
- **Dynamic Database**: 100+ technical skills with fuzzy matching
- **Importance Weighting**: High/medium/low importance levels
- **Related Skills**: Compensation for missing skills with related ones
- **Coverage Analysis**: Detailed skills gap analysis

### Validation System
- **Multi-Layer Scoring**: Combines semantic, skills, and LLM scores
- **Confidence Metrics**: Reliability indicators
- **Anomaly Detection**: Flags inconsistent results
- **Score Adjustment**: Intelligent score normalization

## ğŸ”’ Security

- **CORS Configuration**: Properly configured for production
- **File Validation**: PDF type and size validation
- **Environment Variables**: Secure API key management
- **Input Sanitization**: Protection against malicious inputs

## ğŸ“ˆ Performance

- **Model Caching**: Efficient model loading and caching
- **Async Processing**: Non-blocking API calls
- **Memory Optimization**: Efficient text processing
- **Response Time**: Typically 5-15 seconds for analysis

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Deployment Issues**: Check [DEPLOYMENT.md](./DEPLOYMENT.md)
- **Local Development**: Use the setup scripts provided
- **API Documentation**: Available at `/docs` when backend is running
- **GitHub Issues**: Create an issue for bugs or feature requests

---

**Made with â¤ï¸ for better job matching** 